{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pet Breed Classification with FastAI\n",
    "\n",
    "This notebook implements a pet breed classifier using FastAI and a pre-trained ResNet34 model. We'll go through:\n",
    "\n",
    "1. Data preparation and loading\n",
    "2. Model setup and training\n",
    "3. Performance evaluation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import required libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfastai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mall\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from fastai.vision.all import *\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "First, we'll set up our data processing pipeline. The images should be organized in the `data` directory with filenames starting with their category names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category extraction function\n",
    "def get_category(fname):\n",
    "    return fname.split('_')[0]  # Extract category name before underscore\n",
    "\n",
    "# Set data path\n",
    "path = Path('data')\n",
    "\n",
    "# Verify data directory exists\n",
    "assert path.exists(), f\"Data directory {path} not found!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataBlock with data augmentation\n",
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    splitter=RandomSplitter(valid_pct=0.2),  # 20% validation set\n",
    "    get_y=lambda x: get_category(x.name),\n",
    "    item_tfms=[Resize(224)],  # Resize images\n",
    "    batch_tfms=[\n",
    "        # Data augmentation transforms\n",
    "        aug_transforms(\n",
    "            mult=1.0,\n",
    "            do_flip=True,\n",
    "            flip_vert=False,\n",
    "            max_rotate=10.0,\n",
    "            min_zoom=1.0,\n",
    "            max_zoom=1.1,\n",
    "            max_lighting=0.2,\n",
    "            max_warp=0.2,\n",
    "            p_affine=0.75,\n",
    "            p_lighting=0.75,\n",
    "        ),\n",
    "        Normalize.from_stats(*imagenet_stats)  # Normalize using ImageNet stats\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "dls = dblock.dataloaders(path, bs=32)\n",
    "\n",
    "# Show a batch of images\n",
    "dls.show_batch(max_n=9, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training\n",
    "\n",
    "We'll use a pre-trained ResNet34 model and fine-tune it for our specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create learner\n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "\n",
    "# Fine-tune the model\n",
    "learn.fine_tune(\n",
    "    epochs=10,\n",
    "    base_lr=3e-3,\n",
    "    freeze_epochs=3,  # Train with frozen layers first\n",
    "    cbs=[\n",
    "        ShowGraphCallback(),  # Show training progress\n",
    "        SaveModelCallback(monitor='valid_loss'),  # Save best model\n",
    "        ReduceLROnPlateau(monitor='valid_loss', patience=2)  # Adaptive learning rate\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation\n",
    "\n",
    "Let's analyze the model's performance using various visualization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interpretation\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 12))\n",
    "interp.plot_confusion_matrix()\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Show top losses\n",
    "interp.plot_top_losses(9, figsize=(15,11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "learn.export('pet_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Testing\n",
    "\n",
    "Test the model on some sample images to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict on a single image\n",
    "def predict_image(img_path):\n",
    "    img = PILImage.create(img_path)\n",
    "    pred, pred_idx, probs = learn.predict(img)\n",
    "    return f'Prediction: {pred}\n",
    "Probability: {probs[pred_idx]:.4f}'\n",
    "\n",
    "# Test on a sample image (uncomment and modify path as needed)\n",
    "# img_path = 'path/to/test/image.jpg'\n",
    "# print(predict_image(img_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
