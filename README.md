# FastAI Pet Breed Classifier
# FastAI å® ç‰©å“ç§åˆ†ç±»å™¨

A deep learning pet breed classification system built with FastAI, PyTorch, and Gradio.
åŸºäº FastAIã€PyTorch å’Œ Gradio æ„å»ºçš„æ·±åº¦å­¦ä¹ å® ç‰©å“ç§åˆ†ç±»ç³»ç»Ÿã€‚

## Project Overview
## é¡¹ç›®æ¦‚è¿°

This project implements a pet breed classification system with the following features:
æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå…·æœ‰ä»¥ä¸‹ç‰¹æ€§çš„å® ç‰©å“ç§åˆ†ç±»ç³»ç»Ÿï¼š

- Real-time pet breed classification using ResNet34 pre-trained model
- ä½¿ç”¨ ResNet34 é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå®æ—¶å® ç‰©å“ç§åˆ†ç±»
- Web interface for image upload and prediction
- ç”¨äºå›¾ç‰‡ä¸Šä¼ å’Œé¢„æµ‹çš„ Web ç•Œé¢
- System resource monitoring (CPU, RAM, GPU)
- ç³»ç»Ÿèµ„æºç›‘æ§ï¼ˆCPUã€å†…å­˜ã€GPUï¼‰
- Docker deployment support
- Docker å®¹å™¨åŒ–éƒ¨ç½²æ”¯æŒ

## Live Demo
## åœ¨çº¿æ¼”ç¤º

Try out the live demo on Hugging Face Spaces:
åœ¨ Hugging Face Spaces ä¸Šè¯•ç”¨åœ¨çº¿æ¼”ç¤ºï¼š

ğŸ”— [Pet Breed Classifier Demo](https://huggingface.co/spaces/JinApang/pet_classifier)

## Project Structure
## é¡¹ç›®ç»“æ„

```
/pet-classifier
â”œâ”€â”€ notebooks/          # Jupyter notebooks for development
â”œâ”€â”€ src/               # Source code
â”œâ”€â”€ docker/            # Docker configuration
â”œâ”€â”€ data/              # Training data directory
â”œâ”€â”€ models/            # Saved model directory
â”œâ”€â”€ requirements.txt   # Project dependencies
â””â”€â”€ README.md         # Project documentation
```

## Dataset Preparation
## æ•°æ®é›†å‡†å¤‡

Use the provided script to download and extract the Oxford-IIIT Pet Dataset:
ä½¿ç”¨æä¾›çš„è„šæœ¬ä¸‹è½½å¹¶è§£å‹ Oxford-IIIT Pet Datasetï¼š

```bash
# Download and extract the dataset
# ä¸‹è½½å¹¶è§£å‹æ•°æ®é›†
./download_dataset.sh
```

This will automatically download and prepare the dataset in the correct format for training.
è¿™å°†è‡ªåŠ¨ä¸‹è½½æ•°æ®é›†å¹¶å‡†å¤‡å¥½ç”¨äºè®­ç»ƒçš„æ­£ç¡®æ ¼å¼ã€‚

## Container Script Usage
## å®¹å™¨è„šæœ¬ä½¿ç”¨è¯´æ˜

The `run_container.sh` script provides a convenient way to manage model training with different configurations.
`run_container.sh` è„šæœ¬æä¾›äº†ä¸€ç§ä¾¿æ·çš„æ–¹å¼æ¥ç®¡ç†ä¸åŒé…ç½®çš„æ¨¡å‹è®­ç»ƒã€‚

### Basic Usage
### åŸºæœ¬ç”¨æ³•

```bash
# Start the container script and follow the interactive menu
# å¯åŠ¨å®¹å™¨è„šæœ¬å¹¶æŒ‰ç…§äº¤äº’å¼èœå•æ“ä½œ
./run_container.sh
```

The script will present a menu with the following options:
è„šæœ¬å°†æ˜¾ç¤ºä»¥ä¸‹é€‰é¡¹çš„èœå•ï¼š

1. Use existing model (no training)
   ä½¿ç”¨ç°æœ‰æ¨¡å‹ï¼ˆä¸è¿›è¡Œè®­ç»ƒï¼‰
2. Quick training mode (1 epoch each phase)
   å¿«é€Ÿè®­ç»ƒæ¨¡å¼ï¼ˆæ¯ä¸ªé˜¶æ®µ1è½®ï¼‰
3. Full training with custom configuration
   ä½¿ç”¨è‡ªå®šä¹‰é…ç½®è¿›è¡Œå®Œæ•´è®­ç»ƒ
4. Use specific model file
   ä½¿ç”¨ç‰¹å®šçš„æ¨¡å‹æ–‡ä»¶
5. Exit
   é€€å‡º

### Advanced Usage
### é«˜çº§ç”¨æ³•

When selecting option 3 (Full training with custom configuration), you can customize the following parameters:
é€‰æ‹©é€‰é¡¹ 3ï¼ˆä½¿ç”¨è‡ªå®šä¹‰é…ç½®è¿›è¡Œå®Œæ•´è®­ç»ƒï¼‰æ—¶ï¼Œæ‚¨å¯ä»¥è‡ªå®šä¹‰ä»¥ä¸‹å‚æ•°ï¼š

- Number of epochs for frozen layers (é»˜è®¤ï¼š5)
- Number of epochs for unfrozen layers (é»˜è®¤ï¼š10)
- Learning rate for frozen layers (é»˜è®¤ï¼š1e-3)
- Minimum learning rate for unfrozen layers (é»˜è®¤ï¼š1e-6)
- Maximum learning rate for unfrozen layers (é»˜è®¤ï¼š1e-4)

When selecting option 4 (Use specific model file), you can specify the model path relative to the models directory.
é€‰æ‹©é€‰é¡¹ 4ï¼ˆä½¿ç”¨ç‰¹å®šçš„æ¨¡å‹æ–‡ä»¶ï¼‰æ—¶ï¼Œæ‚¨å¯ä»¥æŒ‡å®šç›¸å¯¹äº models ç›®å½•çš„æ¨¡å‹è·¯å¾„ã€‚

### Docker Environment
### Docker ç¯å¢ƒ

The `run_container.sh` script manages Docker containers with the following features:
`run_container.sh` è„šæœ¬ç®¡ç†å…·æœ‰ä»¥ä¸‹ç‰¹æ€§çš„ Docker å®¹å™¨ï¼š

- Automatically checks if Docker and NVIDIA Docker runtime are installed
  è‡ªåŠ¨æ£€æŸ¥æ˜¯å¦å®‰è£…äº† Docker å’Œ NVIDIA Docker è¿è¡Œæ—¶
- Builds the Docker image if it doesn't exist
  å¦‚æœ Docker é•œåƒä¸å­˜åœ¨ï¼Œåˆ™æ„å»ºå®ƒ
- Mounts data and models directories for persistence
  æŒ‚è½½æ•°æ®å’Œæ¨¡å‹ç›®å½•ä»¥å®ç°æŒä¹…åŒ–
- Configures GPU access for training
  é…ç½®ç”¨äºè®­ç»ƒçš„ GPU è®¿é—®æƒé™

## Docker Deployment
## Docker éƒ¨ç½²

1. Build Docker image:
1. æ„å»º Docker é•œåƒï¼š
```bash
docker build -t pet-classifier .
```

2. Run container with different configurations:
2. ä½¿ç”¨ä¸åŒé…ç½®è¿è¡Œå®¹å™¨ï¼š

### Basic run (use existing model if available, train if not):
### åŸºæœ¬è¿è¡Œï¼ˆå¦‚æœæœ‰ç°æœ‰æ¨¡å‹åˆ™ä½¿ç”¨ï¼Œå¦åˆ™è®­ç»ƒï¼‰ï¼š
```bash
docker run --gpus all --shm-size=1g -p 7860:7860 \
    -v ./data:/app/data \
    -v ./models:/app/models \
    --name pet-classifier \
    --rm pet-classifier
```

### Force retrain (ignore existing model):
### å¼ºåˆ¶é‡æ–°è®­ç»ƒï¼ˆå¿½ç•¥ç°æœ‰æ¨¡å‹ï¼‰ï¼š
```bash
docker run --gpus all --shm-size=1g -p 7860:7860 \
    -v ./data:/app/data \
    -v ./models:/app/models \
    --name pet-classifier \
    --rm pet-classifier \
    python src/pet_classifier.py --retrain
```

### Use specific model without training:
### ä½¿ç”¨æŒ‡å®šæ¨¡å‹ï¼ˆä¸è¿›è¡Œè®­ç»ƒï¼‰ï¼š
```bash
docker run --gpus all --shm-size=1g -p 7860:7860 \
    -v ./data:/app/data \
    -v ./models:/app/models \
    --name pet-classifier \
    --rm pet-classifier \
    python src/pet_classifier.py --model-path models/my_custom_model.pkl
```

### Quick training mode (1 epoch each phase):
### å¿«é€Ÿè®­ç»ƒæ¨¡å¼ï¼ˆæ¯ä¸ªé˜¶æ®µ 1 è½®ï¼‰ï¼š
```bash
docker run --gpus all --shm-size=1g -p 7860:7860 \
    -v ./data:/app/data \
    -v ./models:/app/models \
    --name pet-classifier \
    --rm pet-classifier \
    python src/pet_classifier.py --retrain --quick-train
```

### Custom Training Epochs:
### è‡ªå®šä¹‰è®­ç»ƒè½®æ¬¡ï¼š
```bash
docker run --gpus all --shm-size=1g -p 7860:7860 \
    -v ./data:/app/data \
    -v ./models:/app/models \
    --name pet-classifier \
    --rm pet-classifier \
    python src/pet_classifier.py --retrain --epochs-frozen 5 --epochs-unfrozen 10
```

### Full training with custom configuration:
### ä½¿ç”¨è‡ªå®šä¹‰é…ç½®çš„å®Œæ•´è®­ç»ƒï¼š
```bash
docker run --gpus all --shm-size=1g -p 7860:7860 \
    -v ./data:/app/data \
    -v ./models:/app/models \
    --name pet-classifier \
    --rm pet-classifier \
    python src/pet_classifier.py --retrain \
        --epochs-frozen 5 \
        --epochs-unfrozen 10 \
        --lr-frozen 1e-3 \
        --lr-unfrozen 1e-5 \
        --model-path models/custom_model.pkl
```

## Auto Training and Deployment
## è‡ªåŠ¨è®­ç»ƒå’Œéƒ¨ç½²

The `auto_train.sh` script provides a convenient way to retrain the model with default parameters and publish it to Hugging Face Spaces.
`auto_train.sh` è„šæœ¬æä¾›äº†ä¸€ç§ä¾¿æ·çš„æ–¹å¼æ¥ä½¿ç”¨é»˜è®¤å‚æ•°é‡æ–°è®­ç»ƒæ¨¡å‹å¹¶å°†å…¶å‘å¸ƒåˆ° Hugging Face Spacesã€‚

### Usage
### ä½¿ç”¨æ–¹æ³•

```bash
# Make the script executable
# ä½¿è„šæœ¬å¯æ‰§è¡Œ
chmod +x auto_train.sh

# Run the auto training and deployment script
# è¿è¡Œè‡ªåŠ¨è®­ç»ƒå’Œéƒ¨ç½²è„šæœ¬
./auto_train.sh
```

The script will:
è¯¥è„šæœ¬å°†ï¼š

1. Retrain the model with the following default parameters:
   ä½¿ç”¨ä»¥ä¸‹é»˜è®¤å‚æ•°é‡æ–°è®­ç»ƒæ¨¡å‹ï¼š
   - Frozen epochs: 5
   - Unfrozen epochs: 10
   - Frozen learning rate: 1e-3
   - Unfrozen learning rate: 1e-5

2. Save the model to `models/pet_classifier.pkl`
   å°†æ¨¡å‹ä¿å­˜åˆ° `models/pet_classifier.pkl`

3. Publish the model to your Hugging Face Space
   å°†æ¨¡å‹å‘å¸ƒåˆ°æ‚¨çš„ Hugging Face Space

4. Update the README on Hugging Face with training information
   ä½¿ç”¨è®­ç»ƒä¿¡æ¯æ›´æ–° Hugging Face ä¸Šçš„ README

### GitHub Actions Integration
### GitHub Actions é›†æˆ

This project includes a GitHub Actions workflow that can automatically train and publish your model to Hugging Face Spaces.
æœ¬é¡¹ç›®åŒ…å«ä¸€ä¸ª GitHub Actions å·¥ä½œæµï¼Œå¯ä»¥è‡ªåŠ¨è®­ç»ƒæ¨¡å‹å¹¶å‘å¸ƒåˆ° Hugging Face Spacesã€‚

#### Setting up Hugging Face Token in GitHub
#### åœ¨ GitHub ä¸­è®¾ç½® Hugging Face ä»¤ç‰Œ

To allow GitHub Actions to publish to your Hugging Face Space, you need to add your Hugging Face token as a GitHub secret:
è¦å…è®¸ GitHub Actions å‘å¸ƒåˆ°æ‚¨çš„ Hugging Face Spaceï¼Œæ‚¨éœ€è¦å°† Hugging Face ä»¤ç‰Œæ·»åŠ ä¸º GitHub å¯†é’¥ï¼š

1. Generate a Hugging Face token:
1. ç”Ÿæˆ Hugging Face ä»¤ç‰Œï¼š
   - Go to [Hugging Face Settings](https://huggingface.co/settings/tokens)
   - Click "New token"
   - Select "Write" access
   - Give it a name (e.g., "GitHub Actions")
   - Click "Generate token"
   - Copy the generated token

2. Add the token to GitHub repository secrets:
2. å°†ä»¤ç‰Œæ·»åŠ åˆ° GitHub ä»“åº“å¯†é’¥ï¼š
   - Go to your GitHub repository
   - Click on "Settings" > "Secrets and variables" > "Actions"
   - Click "New repository secret"
   - Name: `HUGGINGFACE_TOKEN`
   - Value: Paste your Hugging Face token
   - Click "Add secret"

Once configured, the GitHub Actions workflow can be triggered manually from the "Actions" tab in your repository.
é…ç½®å®Œæˆåï¼Œå¯ä»¥ä»ä»“åº“çš„ "Actions" æ ‡ç­¾é¡µæ‰‹åŠ¨è§¦å‘ GitHub Actions å·¥ä½œæµã€‚

#### Troubleshooting GitHub Actions
#### GitHub Actions æ•…éšœæ’é™¤

If you encounter authentication issues with Hugging Face in GitHub Actions:
å¦‚æœæ‚¨åœ¨ GitHub Actions ä¸­é‡åˆ° Hugging Face çš„èº«ä»½éªŒè¯é—®é¢˜ï¼š

1. Make sure your `HUGGINGFACE_TOKEN` secret is correctly set in the repository settings
1. ç¡®ä¿æ‚¨çš„ `HUGGINGFACE_TOKEN` å¯†é’¥åœ¨ä»“åº“è®¾ç½®ä¸­æ­£ç¡®è®¾ç½®
2. Check that your token has write permissions for the Hugging Face space
2. æ£€æŸ¥æ‚¨çš„ä»¤ç‰Œå¯¹ Hugging Face space å…·æœ‰å†™å…¥æƒé™
3. Verify the Hugging Face space name in the `auto_train.sh` script is correct
3. éªŒè¯ `auto_train.sh` è„šæœ¬ä¸­çš„ Hugging Face space åç§°æ˜¯å¦æ­£ç¡®

The workflow is configured to use non-interactive authentication for CI environments, avoiding the terminal interaction issues.
å·¥ä½œæµç¨‹é…ç½®ä¸ºåœ¨ CI ç¯å¢ƒä¸­ä½¿ç”¨éäº¤äº’å¼èº«ä»½éªŒè¯ï¼Œé¿å…ç»ˆç«¯äº¤äº’é—®é¢˜ã€‚

### Requirements
### è¦æ±‚

- Hugging Face CLI (`pip install huggingface-hub`)
- Git LFS (for handling large model files)
- Valid Hugging Face credentials with write access to your space

## Development Environment
## å¼€å‘ç¯å¢ƒ

- Windows + WSL2
- Python virtual environmentï¼ˆPython è™šæ‹Ÿç¯å¢ƒï¼‰
- VSCode + JupyterLab
- GPU: 12GB VRAM
- RAM: 32GB

## Tech Stack
## æŠ€æœ¯æ ˆ

- FastAI + PyTorch (ResNet34 pre-trained model)
- JupyterLab (development environment)
- Gradio (Web UI)
- Docker (deployment)

## Setup Instructions
## å®‰è£…è¯´æ˜

1. Create and activate Python virtual environment:
1. åˆ›å»ºå¹¶æ¿€æ´» Python è™šæ‹Ÿç¯å¢ƒï¼š
```bash
python -m venv venv
source venv/bin/activate  # On Linux/WSL2
# or
venv\Scripts\activate  # On Windows
```

2. Install dependencies:
2. å®‰è£…ä¾èµ–ï¼š
```bash
pip install -r requirements.txt
```

3. Prepare your training data in the `data` directory with the following structure:
3. åœ¨ `data` ç›®å½•ä¸­å‡†å¤‡è®­ç»ƒæ•°æ®ï¼Œç»“æ„å¦‚ä¸‹ï¼š
```
data/
  â”œâ”€â”€ breed1_image1.jpg
  â”œâ”€â”€ breed1_image2.jpg
  â”œâ”€â”€ breed2_image1.jpg
  â””â”€â”€ ...
```
Note: Image filenames should start with the breed name followed by an underscore.
æ³¨æ„ï¼šå›¾ç‰‡æ–‡ä»¶ååº”ä»¥å“ç§åç§°å¼€å¤´ï¼Œåè·Ÿä¸‹åˆ’çº¿ã€‚

## Training and Running the Model
## æ¨¡å‹è®­ç»ƒä¸è¿è¡Œ

### Basic Usage python
### åŸºæœ¬ç”¨æ³• python

Start the classifier with default settings:
ä½¿ç”¨é»˜è®¤è®¾ç½®å¯åŠ¨åˆ†ç±»å™¨ï¼š
```bash
python src/pet_classifier.py
```
This will:
è¿™å°†ä¼šï¼š
- Load the pre-trained model if available at `models/pet_classifier.pkl`
- å¦‚æœå­˜åœ¨ï¼ŒåŠ è½½ä½äº `models/pet_classifier.pkl` çš„é¢„è®­ç»ƒæ¨¡å‹
- Train a new model if no pre-trained model exists
- å¦‚æœæ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼Œè®­ç»ƒä¸€ä¸ªæ–°æ¨¡å‹
- Launch the Gradio web interface at http://localhost:7860
- åœ¨ http://localhost:7860 å¯åŠ¨ Gradio Web ç•Œé¢

### Training Options
### è®­ç»ƒé€‰é¡¹

1. Force retrain the model (ignore existing model):
1. å¼ºåˆ¶é‡æ–°è®­ç»ƒæ¨¡å‹ï¼ˆå¿½ç•¥ç°æœ‰æ¨¡å‹ï¼‰ï¼š
```bash
python src/pet_classifier.py --retrain
```

2. Use a specific model file:
2. ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹æ–‡ä»¶ï¼š
```bash
python src/pet_classifier.py --model-path models/my_custom_model.pkl
```

3. Force retrain with a custom save path:
3. å¼ºåˆ¶é‡æ–°è®­ç»ƒå¹¶ä½¿ç”¨è‡ªå®šä¹‰ä¿å­˜è·¯å¾„ï¼š
```bash
python src/pet_classifier.py --retrain --model-path models/new_model.pkl
```

### Advanced Training Configurations
### é«˜çº§è®­ç»ƒé…ç½®

1. Train with more epochs (5 epochs for frozen layers, 10 for fine-tuning):
1. ä½¿ç”¨æ›´å¤šè®­ç»ƒè½®æ¬¡ï¼ˆå†»ç»“å±‚ 5 è½®ï¼Œå¾®è°ƒ 10 è½®ï¼‰ï¼š
```bash
python src/pet_classifier.py --retrain --epochs-frozen 5 --epochs-unfrozen 10
```

2. Train with custom learning rates:
2. ä½¿ç”¨è‡ªå®šä¹‰å­¦ä¹ ç‡ï¼š
```bash
python src/pet_classifier.py --retrain --lr-frozen 1e-3 --lr-unfrozen 1e-5
```

3. Combined training configuration:
3. ç»„åˆè®­ç»ƒé…ç½®ï¼š
```bash
python src/pet_classifier.py --retrain \
    --epochs-frozen 5 \
    --epochs-unfrozen 10 \
    --lr-frozen 1e-3 \
    --lr-unfrozen 1e-5 \
    --model-path models/custom_model.pkl
```

4. Quick training mode (1 epoch each phase):
4. å¿«é€Ÿè®­ç»ƒæ¨¡å¼ï¼ˆæ¯ä¸ªé˜¶æ®µ 1 è½®ï¼‰ï¼š
```bash
python src/pet_classifier.py --retrain --quick-train
```

5. Full training mode with larger image size:
5. ä½¿ç”¨æ›´å¤§å›¾ç‰‡å°ºå¯¸çš„å®Œæ•´è®­ç»ƒæ¨¡å¼ï¼š
```bash
python src/pet_classifier.py --retrain --image-size 448 --batch-size 16
```

## Usage
## ä½¿ç”¨è¯´æ˜

1. Access the web interface at http://localhost:7860
1. è®¿é—® Web ç•Œé¢ï¼šhttp://localhost:7860
2. Upload a pet image
2. ä¸Šä¼ å® ç‰©å›¾ç‰‡
3. Get real-time breed classification results with confidence scores
3. è·å–å®æ—¶å“ç§åˆ†ç±»ç»“æœå’Œç½®ä¿¡åº¦åˆ†æ•°
4. Monitor system resource usage during inference
4. ç›‘æ§æ¨ç†è¿‡ç¨‹ä¸­çš„ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ

## Development Workflow
## å¼€å‘å·¥ä½œæµç¨‹

1. Local development (Python virtual environment + VSCode)
1. æœ¬åœ°å¼€å‘ï¼ˆPython è™šæ‹Ÿç¯å¢ƒ + VSCodeï¼‰
2. Model training and testing (Jupyter Notebook)
2. æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•ï¼ˆJupyter Notebookï¼‰
3. Packaging and deployment (Docker)
3. æ‰“åŒ…å’Œéƒ¨ç½²ï¼ˆDockerï¼‰

## Docker Resource Optimization
## Docker èµ„æºä¼˜åŒ–

This project includes tools and configurations for optimizing Docker resource usage.
æœ¬é¡¹ç›®åŒ…å«ç”¨äºä¼˜åŒ– Docker èµ„æºä½¿ç”¨çš„å·¥å…·å’Œé…ç½®ã€‚

### Docker Cleanup Script
### Docker æ¸…ç†è„šæœ¬

The `docker-cleanup.sh` script helps manage Docker resources and optimize disk space:
`docker-cleanup.sh` è„šæœ¬å¸®åŠ©ç®¡ç† Docker èµ„æºå¹¶ä¼˜åŒ–ç£ç›˜ç©ºé—´ï¼š

```bash
# Make the script executable
# ä½¿è„šæœ¬å¯æ‰§è¡Œ
chmod +x docker-cleanup.sh

# Run the Docker cleanup utility
# è¿è¡Œ Docker æ¸…ç†å·¥å…·
./docker-cleanup.sh
```

The script provides options for:
è„šæœ¬æä¾›ä»¥ä¸‹é€‰é¡¹ï¼š

- Removing unused containers
  ç§»é™¤æœªä½¿ç”¨çš„å®¹å™¨
- Removing unused images
  ç§»é™¤æœªä½¿ç”¨çš„é•œåƒ
- Removing unused volumes
  ç§»é™¤æœªä½¿ç”¨çš„å·
- Removing unused networks
  ç§»é™¤æœªä½¿ç”¨çš„ç½‘ç»œ
- Complete system cleanup
  å®Œæ•´çš„ç³»ç»Ÿæ¸…ç†
- Advanced cleanup (including builder cache)
  é«˜çº§æ¸…ç†ï¼ˆåŒ…æ‹¬æ„å»ºç¼“å­˜ï¼‰

### Docker Optimization Tips
### Docker ä¼˜åŒ–æŠ€å·§

1. **Layer Caching**: Structure your Dockerfile with frequently changing content at the bottom to maximize cache usage.
   **å±‚ç¼“å­˜**: å°†é¢‘ç¹å˜åŒ–çš„å†…å®¹æ”¾åœ¨ Dockerfile åº•éƒ¨ï¼Œä»¥æœ€å¤§åŒ–ç¼“å­˜ä½¿ç”¨ã€‚

2. **Regular Cleanup**: Run the cleanup script regularly to prevent excess resource usage:
   **å®šæœŸæ¸…ç†**: å®šæœŸè¿è¡Œæ¸…ç†è„šæœ¬ä»¥é˜²æ­¢è¿‡åº¦èµ„æºä½¿ç”¨ï¼š
   ```bash
   # Remove unused containers
   docker container prune

   # Remove unused images
   docker image prune

   # Remove all unused Docker objects
   docker system prune
   ```

3. **Multi-stage Builds**: Use multi-stage builds in your Dockerfile to reduce final image size.
   **å¤šé˜¶æ®µæ„å»º**: åœ¨ Dockerfile ä¸­ä½¿ç”¨å¤šé˜¶æ®µæ„å»ºä»¥å‡å°æœ€ç»ˆé•œåƒå¤§å°ã€‚

4. **Volume Mounting**: Use volume mounting for development to avoid rebuilding images.
   **å·æŒ‚è½½**: åœ¨å¼€å‘ä¸­ä½¿ç”¨å·æŒ‚è½½ï¼Œé¿å…é‡æ–°æ„å»ºé•œåƒã€‚

5. **Resource Limits**: Configure resource limits in your Docker Compose or run commands.
   **èµ„æºé™åˆ¶**: åœ¨ Docker Compose æˆ–è¿è¡Œå‘½ä»¤ä¸­é…ç½®èµ„æºé™åˆ¶ã€‚

## License
## è®¸å¯è¯

MIT License
MIT è®¸å¯è¯
