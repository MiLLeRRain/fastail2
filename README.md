# FastAI Pet Breed Classifier
# FastAI å® ç‰©å“ç§åˆ†ç±»å™¨

A deep learning pet breed classification system built with FastAI, PyTorch, and Gradio.
åŸºäº FastAIã€PyTorch å’Œ Gradio æ„å»ºçš„æ·±åº¦å­¦ä¹ å® ç‰©å“ç§åˆ†ç±»ç³»ç»Ÿã€‚

## Project Overview
## é¡¹ç›®æ¦‚è¿°

This project implements a pet breed classification system with the following features:
æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå…·æœ‰ä»¥ä¸‹ç‰¹æ€§çš„å® ç‰©å“ç§åˆ†ç±»ç³»ç»Ÿï¼š

- Real-time pet breed classification using ResNet34 pre-trained model
- ä½¿ç”¨ ResNet34 é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå®æ—¶å® ç‰©å“ç§åˆ†ç±»
- Web interface for image upload and prediction
- ç”¨äºå›¾ç‰‡ä¸Šä¼ å’Œé¢„æµ‹çš„ Web ç•Œé¢
- System resource monitoring (CPU, RAM, GPU)
- ç³»ç»Ÿèµ„æºç›‘æ§ï¼ˆCPUã€å†…å­˜ã€GPUï¼‰
- Docker deployment support
- Docker å®¹å™¨åŒ–éƒ¨ç½²æ”¯æŒ

## Live Demo
## åœ¨çº¿æ¼”ç¤º

Try out the live demo on Hugging Face Spaces:
åœ¨ Hugging Face Spaces ä¸Šè¯•ç”¨åœ¨çº¿æ¼”ç¤ºï¼š

ğŸ”— [Pet Breed Classifier Demo](https://huggingface.co/spaces/JinApang/pet_classifier)

## Project Structure
## é¡¹ç›®ç»“æ„

```
/pet-classifier
â”œâ”€â”€ notebooks/          # Jupyter notebooks for development
â”œâ”€â”€ src/               # Source code
â”œâ”€â”€ docker/            # Docker configuration
â”œâ”€â”€ data/              # Training data directory
â”œâ”€â”€ models/            # Saved model directory
â”œâ”€â”€ requirements.txt   # Project dependencies
â””â”€â”€ README.md         # Project documentation
```

## Dataset Preparation
## æ•°æ®é›†å‡†å¤‡

Use the provided script to download and extract the Oxford-IIIT Pet Dataset:
ä½¿ç”¨æä¾›çš„è„šæœ¬ä¸‹è½½å¹¶è§£å‹ Oxford-IIIT Pet Datasetï¼š

```bash
# Download and extract the dataset
# ä¸‹è½½å¹¶è§£å‹æ•°æ®é›†
./download_dataset.sh
```

This will automatically download and prepare the dataset in the correct format for training.
è¿™å°†è‡ªåŠ¨ä¸‹è½½æ•°æ®é›†å¹¶å‡†å¤‡å¥½ç”¨äºè®­ç»ƒçš„æ­£ç¡®æ ¼å¼ã€‚

## Container Script Usage
## å®¹å™¨è„šæœ¬ä½¿ç”¨è¯´æ˜

The `run_container.sh` script provides a convenient way to manage model training with different configurations.
`run_container.sh` è„šæœ¬æä¾›äº†ä¸€ç§ä¾¿æ·çš„æ–¹å¼æ¥ç®¡ç†ä¸åŒé…ç½®çš„æ¨¡å‹è®­ç»ƒã€‚

### Basic Usage
### åŸºæœ¬ç”¨æ³•

```bash
# Start the container script and follow the interactive menu
# å¯åŠ¨å®¹å™¨è„šæœ¬å¹¶æŒ‰ç…§äº¤äº’å¼èœå•æ“ä½œ
./run_container.sh
```

The script will present a menu with the following options:
è„šæœ¬å°†æ˜¾ç¤ºä»¥ä¸‹é€‰é¡¹çš„èœå•ï¼š

1. Use existing model (no training)
   ä½¿ç”¨ç°æœ‰æ¨¡å‹ï¼ˆä¸è¿›è¡Œè®­ç»ƒï¼‰
2. Quick training mode (1 epoch each phase)
   å¿«é€Ÿè®­ç»ƒæ¨¡å¼ï¼ˆæ¯ä¸ªé˜¶æ®µ1è½®ï¼‰
3. Full training with custom configuration
   ä½¿ç”¨è‡ªå®šä¹‰é…ç½®è¿›è¡Œå®Œæ•´è®­ç»ƒ
4. Use specific model file
   ä½¿ç”¨ç‰¹å®šçš„æ¨¡å‹æ–‡ä»¶
5. Exit
   é€€å‡º

### Advanced Usage
### é«˜çº§ç”¨æ³•

When selecting option 3 (Full training with custom configuration), you can customize the following parameters:
é€‰æ‹©é€‰é¡¹ 3ï¼ˆä½¿ç”¨è‡ªå®šä¹‰é…ç½®è¿›è¡Œå®Œæ•´è®­ç»ƒï¼‰æ—¶ï¼Œæ‚¨å¯ä»¥è‡ªå®šä¹‰ä»¥ä¸‹å‚æ•°ï¼š

- Number of epochs for frozen layers (é»˜è®¤ï¼š5)
- Number of epochs for unfrozen layers (é»˜è®¤ï¼š10)
- Learning rate for frozen layers (é»˜è®¤ï¼š1e-3)
- Minimum learning rate for unfrozen layers (é»˜è®¤ï¼š1e-6)
- Maximum learning rate for unfrozen layers (é»˜è®¤ï¼š1e-4)

When selecting option 4 (Use specific model file), you can specify the model path relative to the models directory.
é€‰æ‹©é€‰é¡¹ 4ï¼ˆä½¿ç”¨ç‰¹å®šçš„æ¨¡å‹æ–‡ä»¶ï¼‰æ—¶ï¼Œæ‚¨å¯ä»¥æŒ‡å®šç›¸å¯¹äº models ç›®å½•çš„æ¨¡å‹è·¯å¾„ã€‚

### Docker Environment
### Docker ç¯å¢ƒ

The `run_container.sh` script manages Docker containers with the following features:
`run_container.sh` è„šæœ¬ç®¡ç†å…·æœ‰ä»¥ä¸‹ç‰¹æ€§çš„ Docker å®¹å™¨ï¼š

- Automatically checks if Docker and NVIDIA Docker runtime are installed
  è‡ªåŠ¨æ£€æŸ¥æ˜¯å¦å®‰è£…äº† Docker å’Œ NVIDIA Docker è¿è¡Œæ—¶
- Builds the Docker image if it doesn't exist
  å¦‚æœ Docker é•œåƒä¸å­˜åœ¨ï¼Œåˆ™æ„å»ºå®ƒ
- Mounts data and models directories for persistence
  æŒ‚è½½æ•°æ®å’Œæ¨¡å‹ç›®å½•ä»¥å®ç°æŒä¹…åŒ–
- Configures GPU access for training
  é…ç½®ç”¨äºè®­ç»ƒçš„ GPU è®¿é—®æƒé™

## Docker Deployment
## Docker éƒ¨ç½²

1. Build Docker image:
1. æ„å»º Docker é•œåƒï¼š
```bash
docker build -t pet-classifier .
```

2. Run container with different configurations:
2. ä½¿ç”¨ä¸åŒé…ç½®è¿è¡Œå®¹å™¨ï¼š

### Basic run (use existing model if available, train if not):
### åŸºæœ¬è¿è¡Œï¼ˆå¦‚æœæœ‰ç°æœ‰æ¨¡å‹åˆ™ä½¿ç”¨ï¼Œå¦åˆ™è®­ç»ƒï¼‰ï¼š
```bash
docker run --gpus all --shm-size=1g -p 7860:7860 \
    -v ./data:/app/data \
    -v ./models:/app/models \
    --name pet-classifier \
    --rm pet-classifier
```

### Force retrain (ignore existing model):
### å¼ºåˆ¶é‡æ–°è®­ç»ƒï¼ˆå¿½ç•¥ç°æœ‰æ¨¡å‹ï¼‰ï¼š
```bash
docker run --gpus all --shm-size=1g -p 7860:7860 \
    -v ./data:/app/data \
    -v ./models:/app/models \
    --name pet-classifier \
    --rm pet-classifier \
    python src/pet_classifier.py --retrain
```

### Use specific model without training:
### ä½¿ç”¨æŒ‡å®šæ¨¡å‹ï¼ˆä¸è¿›è¡Œè®­ç»ƒï¼‰ï¼š
```bash
docker run --gpus all --shm-size=1g -p 7860:7860 \
    -v ./data:/app/data \
    -v ./models:/app/models \
    --name pet-classifier \
    --rm pet-classifier \
    python src/pet_classifier.py --model-path models/my_custom_model.pkl
```

### Quick training mode (1 epoch each phase):
### å¿«é€Ÿè®­ç»ƒæ¨¡å¼ï¼ˆæ¯ä¸ªé˜¶æ®µ 1 è½®ï¼‰ï¼š
```bash
docker run --gpus all --shm-size=1g -p 7860:7860 \
    -v ./data:/app/data \
    -v ./models:/app/models \
    --name pet-classifier \
    --rm pet-classifier \
    python src/pet_classifier.py --retrain --quick-train
```

### Custom Training Epochs:
### è‡ªå®šä¹‰è®­ç»ƒè½®æ¬¡ï¼š
```bash
docker run --gpus all --shm-size=1g -p 7860:7860 \
    -v ./data:/app/data \
    -v ./models:/app/models \
    --name pet-classifier \
    --rm pet-classifier \
    python src/pet_classifier.py --retrain --epochs-frozen 5 --epochs-unfrozen 10
```

### Full training with custom configuration:
### ä½¿ç”¨è‡ªå®šä¹‰é…ç½®çš„å®Œæ•´è®­ç»ƒï¼š
```bash
docker run --gpus all --shm-size=1g -p 7860:7860 \
    -v ./data:/app/data \
    -v ./models:/app/models \
    --name pet-classifier \
    --rm pet-classifier \
    python src/pet_classifier.py --retrain \
        --epochs-frozen 5 \
        --epochs-unfrozen 10 \
        --lr-frozen 1e-3 \
        --lr-unfrozen 1e-5 \
        --model-path models/custom_model.pkl
```

## Auto Training and Deployment
## è‡ªåŠ¨è®­ç»ƒå’Œéƒ¨ç½²

The `auto_train.sh` script provides a convenient way to retrain the model with default parameters and publish it to Hugging Face Spaces.
`auto_train.sh` è„šæœ¬æä¾›äº†ä¸€ç§ä¾¿æ·çš„æ–¹å¼æ¥ä½¿ç”¨é»˜è®¤å‚æ•°é‡æ–°è®­ç»ƒæ¨¡å‹å¹¶å°†å…¶å‘å¸ƒåˆ° Hugging Face Spacesã€‚

### Usage
### ä½¿ç”¨æ–¹æ³•

```bash
# Make the script executable
# ä½¿è„šæœ¬å¯æ‰§è¡Œ
chmod +x auto_train.sh

# Run the auto training and deployment script
# è¿è¡Œè‡ªåŠ¨è®­ç»ƒå’Œéƒ¨ç½²è„šæœ¬
./auto_train.sh
```

The script will:
è¯¥è„šæœ¬å°†ï¼š

1. Retrain the model with the following default parameters:
   ä½¿ç”¨ä»¥ä¸‹é»˜è®¤å‚æ•°é‡æ–°è®­ç»ƒæ¨¡å‹ï¼š
   - Frozen epochs: 5
   - Unfrozen epochs: 10
   - Frozen learning rate: 1e-3
   - Unfrozen learning rate: 1e-5

2. Save the model to `models/pet_classifier.pkl`
   å°†æ¨¡å‹ä¿å­˜åˆ° `models/pet_classifier.pkl`

3. Publish the model to your Hugging Face Space
   å°†æ¨¡å‹å‘å¸ƒåˆ°æ‚¨çš„ Hugging Face Space

4. Update the README on Hugging Face with training information
   ä½¿ç”¨è®­ç»ƒä¿¡æ¯æ›´æ–° Hugging Face ä¸Šçš„ README

### Requirements
### è¦æ±‚

- Hugging Face CLI (`pip install huggingface-hub`)
- Git LFS (for handling large model files)
- Valid Hugging Face credentials with write access to your space

## Development Environment
## å¼€å‘ç¯å¢ƒ

- Windows + WSL2
- Python virtual environmentï¼ˆPython è™šæ‹Ÿç¯å¢ƒï¼‰
- VSCode + JupyterLab
- GPU: 12GB VRAM
- RAM: 32GB

## Tech Stack
## æŠ€æœ¯æ ˆ

- FastAI + PyTorch (ResNet34 pre-trained model)
- JupyterLab (development environment)
- Gradio (Web UI)
- Docker (deployment)

## Setup Instructions
## å®‰è£…è¯´æ˜

1. Create and activate Python virtual environment:
1. åˆ›å»ºå¹¶æ¿€æ´» Python è™šæ‹Ÿç¯å¢ƒï¼š
```bash
python -m venv venv
source venv/bin/activate  # On Linux/WSL2
# or
venv\Scripts\activate  # On Windows
```

2. Install dependencies:
2. å®‰è£…ä¾èµ–ï¼š
```bash
pip install -r requirements.txt
```

3. Prepare your training data in the `data` directory with the following structure:
3. åœ¨ `data` ç›®å½•ä¸­å‡†å¤‡è®­ç»ƒæ•°æ®ï¼Œç»“æ„å¦‚ä¸‹ï¼š
```
data/
  â”œâ”€â”€ breed1_image1.jpg
  â”œâ”€â”€ breed1_image2.jpg
  â”œâ”€â”€ breed2_image1.jpg
  â””â”€â”€ ...
```
Note: Image filenames should start with the breed name followed by an underscore.
æ³¨æ„ï¼šå›¾ç‰‡æ–‡ä»¶ååº”ä»¥å“ç§åç§°å¼€å¤´ï¼Œåè·Ÿä¸‹åˆ’çº¿ã€‚

## Training and Running the Model
## æ¨¡å‹è®­ç»ƒä¸è¿è¡Œ

### Basic Usage python
### åŸºæœ¬ç”¨æ³• python

Start the classifier with default settings:
ä½¿ç”¨é»˜è®¤è®¾ç½®å¯åŠ¨åˆ†ç±»å™¨ï¼š
```bash
python src/pet_classifier.py
```
This will:
è¿™å°†ä¼šï¼š
- Load the pre-trained model if available at `models/pet_classifier.pkl`
- å¦‚æœå­˜åœ¨ï¼ŒåŠ è½½ä½äº `models/pet_classifier.pkl` çš„é¢„è®­ç»ƒæ¨¡å‹
- Train a new model if no pre-trained model exists
- å¦‚æœæ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼Œè®­ç»ƒä¸€ä¸ªæ–°æ¨¡å‹
- Launch the Gradio web interface at http://localhost:7860
- åœ¨ http://localhost:7860 å¯åŠ¨ Gradio Web ç•Œé¢

### Training Options
### è®­ç»ƒé€‰é¡¹

1. Force retrain the model (ignore existing model):
1. å¼ºåˆ¶é‡æ–°è®­ç»ƒæ¨¡å‹ï¼ˆå¿½ç•¥ç°æœ‰æ¨¡å‹ï¼‰ï¼š
```bash
python src/pet_classifier.py --retrain
```

2. Use a specific model file:
2. ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹æ–‡ä»¶ï¼š
```bash
python src/pet_classifier.py --model-path models/my_custom_model.pkl
```

3. Force retrain with a custom save path:
3. å¼ºåˆ¶é‡æ–°è®­ç»ƒå¹¶ä½¿ç”¨è‡ªå®šä¹‰ä¿å­˜è·¯å¾„ï¼š
```bash
python src/pet_classifier.py --retrain --model-path models/new_model.pkl
```

### Advanced Training Configurations
### é«˜çº§è®­ç»ƒé…ç½®

1. Train with more epochs (5 epochs for frozen layers, 10 for fine-tuning):
1. ä½¿ç”¨æ›´å¤šè®­ç»ƒè½®æ¬¡ï¼ˆå†»ç»“å±‚ 5 è½®ï¼Œå¾®è°ƒ 10 è½®ï¼‰ï¼š
```bash
python src/pet_classifier.py --retrain --epochs-frozen 5 --epochs-unfrozen 10
```

2. Train with custom learning rates:
2. ä½¿ç”¨è‡ªå®šä¹‰å­¦ä¹ ç‡ï¼š
```bash
python src/pet_classifier.py --retrain --lr-frozen 1e-3 --lr-unfrozen 1e-5
```

3. Combined training configuration:
3. ç»„åˆè®­ç»ƒé…ç½®ï¼š
```bash
python src/pet_classifier.py --retrain \
    --epochs-frozen 5 \
    --epochs-unfrozen 10 \
    --lr-frozen 1e-3 \
    --lr-unfrozen 1e-5 \
    --model-path models/custom_model.pkl
```

4. Quick training mode (1 epoch each phase):
4. å¿«é€Ÿè®­ç»ƒæ¨¡å¼ï¼ˆæ¯ä¸ªé˜¶æ®µ 1 è½®ï¼‰ï¼š
```bash
python src/pet_classifier.py --retrain --quick-train
```

5. Full training mode with larger image size:
5. ä½¿ç”¨æ›´å¤§å›¾ç‰‡å°ºå¯¸çš„å®Œæ•´è®­ç»ƒæ¨¡å¼ï¼š
```bash
python src/pet_classifier.py --retrain --image-size 448 --batch-size 16
```

## Usage
## ä½¿ç”¨è¯´æ˜

1. Access the web interface at http://localhost:7860
1. è®¿é—® Web ç•Œé¢ï¼šhttp://localhost:7860
2. Upload a pet image
2. ä¸Šä¼ å® ç‰©å›¾ç‰‡
3. Get real-time breed classification results with confidence scores
3. è·å–å®æ—¶å“ç§åˆ†ç±»ç»“æœå’Œç½®ä¿¡åº¦åˆ†æ•°
4. Monitor system resource usage during inference
4. ç›‘æ§æ¨ç†è¿‡ç¨‹ä¸­çš„ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ

## Development Workflow
## å¼€å‘å·¥ä½œæµç¨‹

1. Local development (Python virtual environment + VSCode)
1. æœ¬åœ°å¼€å‘ï¼ˆPython è™šæ‹Ÿç¯å¢ƒ + VSCodeï¼‰
2. Model training and testing (Jupyter Notebook)
2. æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•ï¼ˆJupyter Notebookï¼‰
3. Packaging and deployment (Docker)
3. æ‰“åŒ…å’Œéƒ¨ç½²ï¼ˆDockerï¼‰

## License
## è®¸å¯è¯

MIT License
MIT è®¸å¯è¯
